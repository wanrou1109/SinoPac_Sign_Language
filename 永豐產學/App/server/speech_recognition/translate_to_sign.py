import os
import sys
import jieba
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from docx import Document
import faiss
import numpy as np
from typing import Dict, List, Tuple
import re
from zhconv import convert
from langdetect import detect
from deep_translator import GoogleTranslator
from dotenv import load_dotenv


# === ğŸ”‘ è¨­å®š OpenRouter (OpenAI) API Key èˆ‡åƒæ•¸ ===
# === ğŸ”‘ è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ===
load_dotenv()
api_key = os.getenv("OPENROUTER_API_KEY")
base_url = "https://openrouter.ai/api/v1"
client = OpenAI(api_key=api_key, base_url=base_url)

# === è¼‰å…¥ä¸¦æ‹†åˆ†åŠ‡æœ¬èªæ–™ ===
def load_corpus_from_docx(file_path: str, max_len: int = 80) -> List[str]:
    doc = Document(file_path)
    chunks: List[str] = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue
        words = list(jieba.cut(text))
        cur: List[str] = []
        for w in words:
            cur.append(w)
            if len("".join(cur)) >= max_len:
                chunks.append("".join(cur))
                cur = []
        if cur:
            chunks.append("".join(cur))
    return chunks

corpus = load_corpus_from_docx("rag_nlToSign.docx", max_len=80)

# === å»ºç«‹å‘é‡ç´¢å¼• ===
embedder = SentenceTransformer("shibing624/text2vec-base-chinese")
corpus_embeddings = embedder.encode(corpus, convert_to_numpy=True)
dimension = corpus_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(corpus_embeddings)

# === æª¢ç´¢æœ€ç›¸é—œå¥å­ ===
def retrieve_relevant_sentences(query: str, k: int = 5) -> List[str]:
    q_emb = embedder.encode([query], convert_to_numpy=True)
    _, indices = index.search(q_emb, k)
    return [corpus[i] for i in indices[0]]

# === ç¢ºä¿ç¹é«”ä¸­æ–‡è¼¸å‡º ===
def ensure_traditional_chinese(text: str) -> Tuple[str, List[Dict[str,str]]]:
    translator = GoogleTranslator(source='auto', target='zh-TW')
    records: List[Dict[str,str]] = []
    words = text.split()
    result: List[str] = []
    for word in words:
        # ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸² (r'...') ä¾†æ­£ç¢ºè™•ç†æ­£å‰‡è¡¨é”å¼è½‰ç¾©åºåˆ—
        if not re.match(r'^[\u4e00-\u9fff\sï¼Œã€‚ã€]+$', word):
            lang = detect(word)
            if lang not in ('zh-tw','zh-cn'):
                trans = translator.translate(word)
                records.append({'original': word, 'translated': trans, 'detected_lang': lang})
                word = trans
        word = convert(word, 'zh-hant')
        result.append(word)
    return ' '.join(result), records
# === è½‰æ‰‹èªä¸»æµç¨‹ ===
def translate_sentence(user_message: str) -> str:
    related = retrieve_relevant_sentences(user_message)
    context = "\n".join(f"- {s}" for s in related)
    system_prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ‰‹èªç¿»è­¯å°ˆå®¶ï¼Œè«‹å°‡ã€Œè‡ªç„¶èªåºçš„ä¸­æ–‡å¥å­ã€è½‰æ›æˆã€Œæ‰‹èªèªåºã€ã€‚
ä½ **åªèƒ½**ä½¿ç”¨**ç¹é«”ä¸­æ–‡**ï¼ˆæ¨¡ä»¿æ‰‹èªåˆ†è©ï¼‰ï¼Œ**çµ•å°ä¸è¦**è¼¸å‡ºå®Œæ•´çš„å¥å­æ¨™é»æˆ–å¤šé¤˜èªªæ˜ã€‚
**è«‹æ³¨æ„ï¼š**  
1. âœï¸ åªè¼¸å‡ºã€Œæ‰‹èªèªåºã€æ ¼å¼è©ä¸²ï¼Œç”¨ç©ºæ ¼æˆ–æ–·è¡Œåˆ†éš”è©ç´ ã€‚  
2. ğŸ­ å¦‚æœè¼¸å…¥èˆ‡åŠ‡æœ¬ä¾‹å¥ç›¸ä¼¼ï¼Œè«‹ç›¡é‡å¥—ç”¨ç›¸åŒèªåºçµæ§‹ã€‚  
3. âœ… å‡è¨­ä½ æ˜¯è¦ç¿»è­¯çµ¦è½éšœéŠ€è¡Œå®¢æˆ¶çœ‹çš„ï¼Œè«‹å®Œæ•´ç¿»è­¯å®¢æˆ¶çš„å…§å®¹ã€‚

**ç¯„ä¾‹å°ç…§ï¼š**
- è‡ªç„¶ä¸­æ–‡ï¼šæ­¡è¿å…‰è‡¨æœ¬è¡Œ  
  æ‰‹èªèªåºï¼šæ­¡è¿ äººä¾† éŠ€è¡Œ  
- è‡ªç„¶ä¸­æ–‡ï¼šè«‹å•æ‚¨è¦è¾¦ç†ä»€éº¼æœå‹™?  
  æ‰‹èªèªåºï¼šè«‹å• è“‹ç« è“‹ç«  ä»€éº¼  
- è‡ªç„¶ä¸­æ–‡ï¼šè«‹å•æ‚¨è¦é–‹æˆ¶çš„åŸå› æ˜¯?  
  æ‰‹èªèªåºï¼šä½  ç”³è«‹ å­˜æ‘º ç”¨ç”¨ ä»€éº¼
- è‡ªç„¶ä¸­æ–‡ï¼šè«‹å•æ‚¨è¦ä½¿ç”¨å¯¦é«”å­˜æ‘ºé‚„æ˜¯ç‚ºæ‚¨ç”³è«‹ç¶²è·¯éŠ€è¡Œå‘¢?
  æ‰‹èªèªåºï¼šè«‹å• ç¬¬ä¸€ å­˜æ‘º æ‹¿èµ° ç¬¬äºŒ ç¶²è·¯éŠ€è¡Œ æ‰‹æ©Ÿ æ»‘ äºŒé¸ä¸€ å“ª

**åƒè€ƒèªæ–™:**  
{context}
---
è«‹å°‡ä¸‹åˆ—è‡ªç„¶èªåºä¸­æ–‡å¥å­ï¼Œè½‰æ›ç‚ºæ‰‹èªèªåºï¼š
"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user",   "content": user_message}
    ]
    resp = client.chat.completions.create(
        model="qwen/qwen2.5-vl-72b-instruct:free",
        messages=messages
    )
    bot_reply = resp.choices[0].message.content.strip()
    converted, notes = ensure_traditional_chinese(bot_reply)
    if notes:
        note_txt = "\nè¨»ï¼šå·²è½‰ç‚ºç¹é«”ï¼š\n" + "\n".join(f"- {n['original']}â†’{n['translated']}" for n in notes)
        converted += note_txt
    return converted

# === CLI ä»‹é¢ ===
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python translate_to_sign.py \"ä¸­æ–‡å¥å­\"")
        sys.exit(1)
    user_text = sys.argv[1]
    result = translate_sentence(user_text)
    print(result)